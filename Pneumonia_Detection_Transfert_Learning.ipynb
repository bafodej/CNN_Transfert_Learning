{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f82d10",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##  Pneumonia_Detection : \n",
    "\n",
    "\n",
    "###  **OBJECTIF DU PROJET:  :**\n",
    "\n",
    " Utiliser un mod√®le DenseNet121 pr√©-entra√Æn√© pour d√©tecter la pneumonie \n",
    "sur des radios thoraciques..  \n",
    " Application du transfer learning pour am√©liorer la pr√©cision du mod√®le.\n",
    " Utilisation de MLflow pour le suivi des exp√©riences et la gestion des mod√®les. \n",
    " Pr√©traitement des donn√©es avec augmentation pour am√©liorer la robustesse du mod√®le. \n",
    " Modelisation et √©valuation des performances du mod√®le sur un jeu de donn√©es de test.\n",
    "\n",
    "---\n",
    "---\n",
    " D√©tection de Pneumonie avec Transfer Learning  et MLflow\n",
    " Projet : Classification binaire d'images de radios thoraciques\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534236b9",
   "metadata": {},
   "source": [
    "## Configuration gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d169c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Configuration GPU stricte\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Configuration m√©moire GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    " try:\n",
    " for gpu in gpus:\n",
    " tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            # Limite la m√©moire GPU √† 2GB\n",
    " tf.config.experimental.set_virtual_device_configuration(\n",
    " gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)]\n",
    " )\n",
    " print(f\"GPU configur√©: {len(gpus)} GPU(s)\")\n",
    " except RuntimeError as e:\n",
    " print(f\"Erreur GPU: {e}\")\n",
    "\n",
    "# Force l'utilisation CPU si GPU pose probl√®me\n",
    "# tf.config.set_visible_devices([], 'GPU')  # D√©commentez si n√©cessaire\n",
    "\n",
    "print(\"Configuration GPU termin√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a54621",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration TensorFlow AVANT d'utiliser tf\n",
    "print(\"Configuration de TensorFlow...\")\n",
    "\n",
    "# Configuration de la m√©moire GPU (si disponible)\n",
    "try:\n",
    " gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    " if gpus:\n",
    " for gpu in gpus:\n",
    " tf.config.experimental.set_memory_growth(gpu, True)\n",
    " print(f\"GPU d√©tect√© et configur√©: {len(gpus)} GPU(s)\")\n",
    " else:\n",
    " print(\"Utilisation du CPU (aucun GPU d√©tect√©)\")\n",
    "except:\n",
    " print(\"Configuration GPU non disponible, utilisation du CPU\")\n",
    "\n",
    "# Limitation de l'utilisation m√©moire pour stabilit√©\n",
    "try:\n",
    " tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    " tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    " print(\"Threads limit√©s pour optimiser la stabilit√©\")\n",
    "except:\n",
    " print(\"Configuration des threads non disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e17bb",
   "metadata": {},
   "source": [
    "###  Import des biblioth√®ques et packages n√©c√©ssaire :\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Flatten, BatchNormalization \n",
    "from tensorflow.keras.applications import DenseNet121, ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import (\n",
    " EarlyStopping, \n",
    " ReduceLROnPlateau, \n",
    " ModelCheckpoint,\n",
    " TensorBoard\n",
    ")\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    " accuracy_score,\n",
    " precision_score,\n",
    " recall_score,\n",
    " f1_score,\n",
    " confusion_matrix,\n",
    " roc_auc_score,\n",
    " roc_curve,\n",
    " classification_report\n",
    ")\n",
    "\n",
    "# MLflow \n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "# Configuration\n",
    "DATA_PATH = Path(\"data/chest_xray\")\n",
    "print(f\"Imports charg√©s\")\n",
    "print(f\"DATA_PATH: {DATA_PATH} (existe: {DATA_PATH.exists()})\")\n",
    "print(\"Tous les imports r√©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0461d8",
   "metadata": {},
   "source": [
    "## Param√®tres globaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = (224, 224) # Taille d'entr√©e pour DenseNet121\n",
    "BATCH_SIZE = 32 # Batch size r√©duit pour DenseNet (plus lourd)\n",
    "EPOCHS = 75\n",
    "LEARNING_RATE = 0.00005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f4f7ec",
   "metadata": {},
   "source": [
    "## Chemins des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbbfd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure attendue : chest_xray/train/NORMAL et chest_xray/train/PNEUMONIA\n",
    "DATA_PATH = \"chest_xray\"\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, \"train\")\n",
    "VAL_PATH = os.path.join(DATA_PATH, \"val\") \n",
    "TEST_PATH = os.path.join(DATA_PATH, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56078660",
   "metadata": {},
   "source": [
    "## Exploration et pr√©paration des donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00312e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "def explore_dataset(data_path):\n",
    " \"\"\"\n",
    " Explore la structure du dataset et affiche des statistiques\n",
    " \"\"\"\n",
    " print(f\"\\n EXPLORATION DU DATASET\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    " if not os.path.exists(data_path):\n",
    " print(f\"Le dossier {data_path} n'existe pas.\")\n",
    " print(\"V√©rifiez que le dataset est bien dans le dossier 'data/chest_xray'\")\n",
    " print(\"Structure attendue: data/chest_xray/train/, data/chest_xray/val/, data/chest_xray/test/\")\n",
    " print(\"Exploration impossible.\")\n",
    " return False\n",
    " \n",
    " total_images = 0\n",
    " dataset_info = {}\n",
    " \n",
    " for subset in ['train', 'val', 'test']:\n",
    " subset_path = os.path.join(data_path, subset)\n",
    " if os.path.exists(subset_path):\n",
    " print(f\"\\n Dossier {subset.upper()}:\")\n",
    " subset_total = 0\n",
    " dataset_info[subset] = {}\n",
    " \n",
    " for class_name in ['NORMAL', 'PNEUMONIA']:\n",
    " class_path = os.path.join(subset_path, class_name)\n",
    " if os.path.exists(class_path):\n",
    " count = len([f for f in os.listdir(class_path) \n",
    " if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    " print(f\"- {class_name}: {count} images\")\n",
    " dataset_info[subset][class_name] = count\n",
    " subset_total += count\n",
    " else:\n",
    " print(f\"- {class_name}: Dossier manquant \")\n",
    " dataset_info[subset][class_name] = 0\n",
    " \n",
    " print(f\"Total {subset}: {subset_total} images\")\n",
    " total_images += subset_total\n",
    " else:\n",
    " print(f\"\\n Dossier {subset.upper()}: Manquant \")\n",
    " \n",
    " if total_images > 0:\n",
    " print(f\"\\n R√âSUM√â DU DATASET:\")\n",
    " print(f\"Total: {total_images} images\")\n",
    " \n",
    "        # Calcul des pourcentages\n",
    " total_normal = sum([dataset_info[s].get('NORMAL', 0) for s in dataset_info])\n",
    " total_pneumonia = sum([dataset_info[s].get('PNEUMONIA', 0) for s in dataset_info])\n",
    " \n",
    " if total_images > 0:\n",
    " normal_pct = (total_normal / total_images) * 100\n",
    " pneumonia_pct = (total_pneumonia / total_images) * 100\n",
    " print(f\"NORMAL: {total_normal} ({normal_pct:.1f}%)\")\n",
    " print(f\"PNEUMONIA: {total_pneumonia} ({pneumonia_pct:.1f}%)\")\n",
    " \n",
    " if abs(normal_pct - pneumonia_pct) > 20:\n",
    " print(f\"Dataset d√©s√©quilibr√© d√©tect√©!\")\n",
    " \n",
    " return total_images > 0\n",
    "\n",
    "def create_demo_dataset():\n",
    " \"\"\"\n",
    " Cr√©e un dataset de d√©monstration avec des images synth√©tiques\n",
    " pour tester le code sans t√©l√©charger le vrai dataset\n",
    " \"\"\"\n",
    " print(f\"\\n CR√âATION D'UN DATASET DE D√âMONSTRATION\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    " demo_path = \"demo_chest_xray\"\n",
    " \n",
    " if os.path.exists(demo_path):\n",
    " print(f\"Dataset de d√©mo existe d√©j√†: {demo_path}\")\n",
    " return demo_path\n",
    " \n",
    " try:\n",
    "        # Cr√©ation de la structure\n",
    " for subset in ['train', 'val', 'test']:\n",
    " for class_name in ['NORMAL', 'PNEUMONIA']:\n",
    " os.makedirs(os.path.join(demo_path, subset, class_name), exist_ok=True)\n",
    " \n",
    "        # G√©n√©ration d'images synth√©tiques\n",
    " print(\"G√©n√©ration d'images synth√©tiques...\")\n",
    " \n",
    " import numpy as np\n",
    " from PIL import Image\n",
    " \n",
    "        # Nombre d'images par cat√©gorie\n",
    " counts = {\n",
    " 'train': {'NORMAL': 20, 'PNEUMONIA': 30},\n",
    " 'val': {'NORMAL': 5, 'PNEUMONIA': 8},\n",
    " 'test': {'NORMAL': 10, 'PNEUMONIA': 15}\n",
    " }\n",
    " \n",
    " for subset, class_counts in counts.items():\n",
    " for class_name, count in class_counts.items():\n",
    " for i in range(count):\n",
    "                    # G√©n√©ration d'image synth√©tique\n",
    " if class_name == 'NORMAL':\n",
    "                        # Images plus claires pour \"normal\"\n",
    " img_array = np.random.randint(100, 200, (224, 224), dtype=np.uint8)\n",
    " else:\n",
    "                        # Images avec plus de variation pour \"pneumonia\"\n",
    " img_array = np.random.randint(50, 150, (224, 224), dtype=np.uint8)\n",
    "                        # Ajout de quelques \"taches\" pour simuler\n",
    " for _ in range(5):\n",
    " x, y = np.random.randint(0, 200, 2)\n",
    " img_array[x:x+24, y:y+24] = np.random.randint(20, 80)\n",
    " \n",
    "                    # Sauvegarde\n",
    " img = Image.fromarray(img_array, mode='L')\n",
    " filename = f\"{class_name.lower()}_{i+1:03d}.jpg\"\n",
    " filepath = os.path.join(demo_path, subset, class_name, filename)\n",
    " img.save(filepath)\n",
    " \n",
    " print(f\"Dataset de d√©mo cr√©√©: {demo_path}\")\n",
    " print(\"Note: Ce sont des images synth√©tiques pour tester le code uniquement!\")\n",
    " return demo_path\n",
    " \n",
    " except Exception as e:\n",
    " print(f\"Erreur lors de la cr√©ation du dataset de d√©mo: {e}\")\n",
    " return None\n",
    "\n",
    "# Exploration du dataset principal\n",
    "print(\"RECHERCHE DU DATASET PRINCIPAL...\")\n",
    "dataset_exists = explore_dataset(DATA_PATH)\n",
    "\n",
    "# Si pas de dataset principal, proposer le dataset de d√©mo\n",
    "if not dataset_exists:\n",
    " print(f\"\\n SOLUTION TEMPORAIRE: DATASET DE D√âMONSTRATION\")\n",
    " print(\"=\" * 60)\n",
    " print(\"En attendant de t√©l√©charger le vrai dataset, voulez-vous:\")\n",
    " print(\"1. Cr√©er un dataset de d√©monstration pour tester le code\")\n",
    " print(\"2. Passer cette √©tape et continuer sans donn√©es\")\n",
    " print()\n",
    " \n",
    "    # Cr√©ation automatique du dataset de d√©mo pour la d√©monstration\n",
    " demo_path = create_demo_dataset()\n",
    " if demo_path:\n",
    " print(f\"\\n Utilisation du dataset de d√©mo pour la suite...\")\n",
    " DATA_PATH = demo_path\n",
    " TRAIN_PATH = os.path.join(DATA_PATH, \"train\")\n",
    " VAL_PATH = os.path.join(DATA_PATH, \"val\")\n",
    " TEST_PATH = os.path.join(DATA_PATH, \"test\")\n",
    " dataset_exists = True\n",
    " print(f\"Chemins mis √† jour vers le dataset de d√©mo\")\n",
    " else:\n",
    " print(f\"Impossible de cr√©er le dataset de d√©mo\")\n",
    " \n",
    "print(f\"\\n CHEMINS FINAUX:\")\n",
    "print(f\"- Dataset: {DATA_PATH}\")\n",
    "print(f\"- Entra√Ænement: {TRAIN_PATH}\")\n",
    "print(f\"- Validation: {VAL_PATH}\")\n",
    "print(f\"- Test: {TEST_PATH}\")\n",
    "print(f\"- Dataset disponible: {' Oui' if dataset_exists else ' Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75192703",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(' TensorFlow CPU version:', tf.__version__)\n",
    "print(' Python version:', __import__('sys').version.split()[0])\n",
    "\n",
    "# Test simple\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(10,))])\n",
    "x = tf.random.normal((32, 10))\n",
    "y = model(x)\n",
    "print(' Test r√©ussi - Shape:', y.shape)\n",
    "print(' TensorFlow fonctionne parfaitement!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d9e5c",
   "metadata": {},
   "source": [
    "# CR√âATION DES G√âN√âRATEURS DE DONN√âES AVEC IMAGEDATAGENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators():\n",
    " \"\"\"\n",
    " Cr√©e les g√©n√©rateurs de donn√©es avec ImageDataGenerator\n",
    " \"\"\"\n",
    " print(\"\\n CR√âATION DES G√âN√âRATEURS DE DONN√âES\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    "    # G√©n√©rateur pour l'entra√Ænement avec augmentation de donn√©es\n",
    " train_datagen = ImageDataGenerator(\n",
    " rescale=1./255, # Normalisation [0,1]\n",
    " rotation_range=15, # Rotation ¬±15¬∞\n",
    " width_shift_range=0.1, # D√©calage horizontal 10%\n",
    " height_shift_range=0.1, # D√©calage vertical 10%\n",
    " shear_range=0.1, # Cisaillement\n",
    " zoom_range=0.1, # Zoom ¬±10%\n",
    " horizontal_flip=True, # Retournement horizontal\n",
    " vertical_flip=False, # Pas de retournement vertical pour les radios\n",
    " fill_mode='nearest', # Remplissage pixels\n",
    " brightness_range=[0.8, 1.2] # Variation luminosit√©\n",
    " )\n",
    " \n",
    "    # G√©n√©rateur pour validation et test (sans augmentation)\n",
    " val_test_datagen = ImageDataGenerator(\n",
    " rescale=1./255 # Seulement normalisation\n",
    " )\n",
    " \n",
    " print(\"Param√®tres d'augmentation configur√©s:\")\n",
    " print(\"- Rotation: ¬±15¬∞\")\n",
    " print(\"- D√©calages: ¬±10%\")\n",
    " print(\"- Zoom: ¬±10%\")\n",
    " print(\"- Retournement horizontal: Oui\")\n",
    " print(\"- Variation luminosit√©: 0.8-1.2\")\n",
    " \n",
    " try:\n",
    "        # G√©n√©rateur d'entra√Ænement\n",
    " train_generator = train_datagen.flow_from_directory(\n",
    " TRAIN_PATH,\n",
    " target_size=IMG_SIZE,\n",
    " batch_size=BATCH_SIZE,\n",
    " class_mode='binary', # Classification binaire\n",
    " shuffle=True,\n",
    " seed=42\n",
    " )\n",
    " \n",
    "        # G√©n√©rateur de validation\n",
    " val_generator = val_test_datagen.flow_from_directory(\n",
    " VAL_PATH,\n",
    " target_size=IMG_SIZE,\n",
    " batch_size=BATCH_SIZE,\n",
    " class_mode='binary',\n",
    " shuffle=False\n",
    " )\n",
    " \n",
    "        # G√©n√©rateur de test\n",
    " test_generator = val_test_datagen.flow_from_directory(\n",
    " TEST_PATH,\n",
    " target_size=IMG_SIZE,\n",
    " batch_size=BATCH_SIZE,\n",
    " class_mode='binary',\n",
    " shuffle=False\n",
    " )\n",
    " \n",
    " print(\"\\n G√©n√©rateurs cr√©√©s avec succ√®s!\")\n",
    " print(f\"Classes d√©tect√©es: {train_generator.class_indices}\")\n",
    " print(f\"Nombre de batches d'entra√Ænement: {len(train_generator)}\")\n",
    " print(f\"Nombre de batches de validation: {len(val_generator)}\")\n",
    " print(f\"Nombre de batches de test: {len(test_generator)}\")\n",
    " \n",
    " return train_generator, val_generator, test_generator\n",
    " \n",
    " except Exception as e:\n",
    " print(f\"Erreur lors de la cr√©ation des g√©n√©rateurs: {e}\")\n",
    " print(\"V√©rifiez la structure des dossiers et la pr√©sence des images\")\n",
    " return None, None, None\n",
    "\n",
    "# Cr√©ation des g√©n√©rateurs\n",
    "if dataset_exists:\n",
    " train_gen, val_gen, test_gen = create_data_generators()\n",
    "else:\n",
    " train_gen, val_gen, test_gen = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de484e",
   "metadata": {},
   "source": [
    "## Visualisation d'√©chantillon d'images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(generator, num_samples=8):\n",
    " \"\"\"\n",
    " Affiche quelques √©chantillons du dataset avec leurs labels\n",
    " \"\"\"\n",
    " if generator is None:\n",
    " print(\"G√©n√©rateur non disponible pour la visualisation\")\n",
    " return\n",
    " \n",
    " print(f\"\\n VISUALISATION D'√âCHANTILLONS\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    " try:\n",
    "        # Reset du g√©n√©rateur pour √©viter les probl√®mes\n",
    " generator.reset()\n",
    " \n",
    "        # R√©cup√©ration d'un batch\n",
    " print(\"R√©cup√©ration d'un batch d'images...\")\n",
    " batch_images, batch_labels = next(generator)\n",
    " \n",
    " print(f\"Batch r√©cup√©r√© - Shape: {batch_images.shape}, Labels: {batch_labels.shape}\")\n",
    " print(f\"Range des pixels: [{batch_images.min():.3f}, {batch_images.max():.3f}]\")\n",
    " \n",
    "        # Configuration de matplotlib\n",
    " plt.style.use('default') # Reset du style\n",
    " \n",
    "        # Configuration de la figure\n",
    " fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    " fig.suptitle(\"√âchantillons du Dataset de Radios Thoraciques\", fontsize=16, fontweight='bold')\n",
    " \n",
    "        # Aplatir les axes pour faciliter l'it√©ration\n",
    " axes = axes.flatten()\n",
    " \n",
    " for i in range(min(num_samples, len(batch_images))):\n",
    "            # Affichage de l'image\n",
    " img = batch_images[i]\n",
    " \n",
    "            # V√©rification si l'image est en couleur ou niveaux de gris\n",
    " if len(img.shape) == 3 and img.shape[-1] == 3:\n",
    "                # Image couleur\n",
    " axes[i].imshow(img)\n",
    " else:\n",
    "                # Image en niveaux de gris\n",
    " if len(img.shape) == 3:\n",
    " img = img[:,:,0] # Prendre le premier canal\n",
    " axes[i].imshow(img, cmap='gray')\n",
    " \n",
    "            # D√©termination de la classe et couleur\n",
    " label = \"PNEUMONIA\" if batch_labels[i] == 1 else \"NORMAL\"\n",
    " color = \"red\" if batch_labels[i] == 1 else \"green\"\n",
    " \n",
    "            # Ajout du titre avec la classe\n",
    " axes[i].set_title(f\"Classe: {label}\", color=color, fontsize=12, fontweight='bold')\n",
    " axes[i].axis('off')\n",
    " \n",
    "        # Masquer les sous-graphiques non utilis√©s\n",
    " for i in range(num_samples, len(axes)):\n",
    " axes[i].axis('off')\n",
    " \n",
    " plt.tight_layout()\n",
    " \n",
    "        # Force l'affichage\n",
    " plt.show()\n",
    " \n",
    " print(\"Visualisation termin√©e!\")\n",
    " \n",
    " except Exception as e:\n",
    " print(f\"Erreur lors de la visualisation: {e}\")\n",
    " print(\"Causes possibles:\")\n",
    " print(\"- Dataset non trouv√© ou mal structur√©\")\n",
    " print(\"- Probl√®me avec les g√©n√©rateurs de donn√©es\")\n",
    " print(\"- Probl√®me d'affichage matplotlib\")\n",
    "\n",
    "# Visualisation des √©chantillons\n",
    "if train_gen is not None:\n",
    " visualize_samples(train_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47502662",
   "metadata": {},
   "source": [
    "## Cr√©ation du mod√®le avec Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_densenet_model():\n",
    " \"\"\"\n",
    " Cr√©e un mod√®le utilisant DenseNet121 pr√©-entra√Æn√© avec transfer learning\n",
    " \"\"\"\n",
    " print(f\"\\n CR√âATION DU MOD√àLE AVEC DENSENET121\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    " try:\n",
    "        # Nettoyage de la m√©moire\n",
    " tf.keras.backend.clear_session()\n",
    " \n",
    "        # Chargement du mod√®le DenseNet121 pr√©-entra√Æn√©\n",
    " print(\"Chargement de DenseNet121 pr√©-entra√Æn√©...\")\n",
    " base_model = DenseNet121(\n",
    " weights='imagenet', # Poids pr√©-entra√Æn√©s sur ImageNet\n",
    " include_top=False, # Exclusion de la couche de classification\n",
    " input_shape=(*IMG_SIZE, 3), # Forme d'entr√©e (224, 224, 3)\n",
    " pooling=None # Pas de pooling automatique\n",
    " )\n",
    " \n",
    "        # Gel des couches pr√©-entra√Æn√©es pour le transfer learning\n",
    " base_model.trainable = False\n",
    " \n",
    " print(f\"Mod√®le de base DenseNet121:\")\n",
    " print(f\"- Nombre de couches: {len(base_model.layers)}\")\n",
    " print(f\"- Param√®tres totaux: {base_model.count_params():,}\")\n",
    " print(f\"- Param√®tres entra√Ænables: {sum([tf.keras.backend.count_params(w) for w in base_model.trainable_weights]):,}\")\n",
    " \n",
    "        # Construction du mod√®le complet\n",
    " inputs = base_model.input\n",
    " x = base_model.output\n",
    " \n",
    "        # Ajout de couches personnalis√©es pour la classification binaire\n",
    " x = GlobalAveragePooling2D(name='global_avg_pooling')(x)\n",
    " x = Dense(256, activation='relu', name='dense_256')(x)\n",
    " x = Dropout(0.5, name='dropout_0.5')(x)\n",
    " x = Dense(128, activation='relu', name='dense_128')(x)\n",
    " x = Dropout(0.3, name='dropout_0.3')(x)\n",
    " \n",
    "        # Couche de sortie pour classification binaire\n",
    " outputs = Dense(1, activation='sigmoid', name='predictions')(x)\n",
    " \n",
    "        # Cr√©ation du mod√®le final\n",
    " model = Model(inputs, outputs, name='DenseNet121_Pneumonia')\n",
    " \n",
    "        # Compilation du mod√®le (CORRIG√âE pour √©viter les erreurs)\n",
    " model.compile(\n",
    " optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    " loss='binary_crossentropy',\n",
    " metrics=['accuracy'] # Seulement accuracy pour √©viter les bugs TensorFlow\n",
    " )\n",
    " \n",
    " print(f\"Mod√®le cr√©√© et compil√©!\")\n",
    " print(f\"Optimiseur: Adam (lr={LEARNING_RATE})\")\n",
    " print(f\"Fonction de perte: binary_crossentropy\")\n",
    " print(f\"M√©triques: accuracy\")\n",
    " print(f\"Param√®tres entra√Ænables totaux: {model.count_params():,}\")\n",
    " \n",
    " return model\n",
    " \n",
    " except Exception as e:\n",
    " print(f\"Erreur lors de la cr√©ation du mod√®le: {e}\")\n",
    " print(\"Essayons avec un mod√®le plus simple...\")\n",
    " return create_simple_fallback_model()\n",
    "\n",
    "def create_simple_fallback_model():\n",
    " \"\"\"\n",
    " Cr√©e un mod√®le CNN simple en cas de probl√®me avec DenseNet121\n",
    " \"\"\"\n",
    " print(f\"\\n MOD√àLE CNN SIMPLE DE SECOURS\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    " try:\n",
    "        # Nettoyage de la m√©moire\n",
    " tf.keras.backend.clear_session()\n",
    " \n",
    " model = tf.keras.Sequential([\n",
    " tf.keras.layers.Input(shape=(*IMG_SIZE, 3)),\n",
    " \n",
    "            # Normalisation\n",
    " tf.keras.layers.Rescaling(1./255),\n",
    " \n",
    "            # Bloc 1\n",
    " tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    " tf.keras.layers.MaxPooling2D(2),\n",
    " \n",
    "            # Bloc 2\n",
    " tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    " tf.keras.layers.MaxPooling2D(2),\n",
    " \n",
    "            # Bloc 3\n",
    " tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    " tf.keras.layers.MaxPooling2D(2),\n",
    " \n",
    "            # Classification\n",
    " tf.keras.layers.GlobalAveragePooling2D(),\n",
    " tf.keras.layers.Dropout(0.3),\n",
    " tf.keras.layers.Dense(128, activation='relu'),\n",
    " tf.keras.layers.Dropout(0.2),\n",
    " tf.keras.layers.Dense(1, activation='sigmoid')\n",
    " ], name='Simple_CNN_Pneumonia')\n",
    " \n",
    "        # Compilation\n",
    " model.compile(\n",
    " optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    " loss='binary_crossentropy',\n",
    " metrics=['accuracy']\n",
    " )\n",
    " \n",
    " print(f\"Mod√®le CNN simple cr√©√©!\")\n",
    " print(f\"Param√®tres totaux: {model.count_params():,}\")\n",
    " print(f\"Mod√®le de secours pour √©viter les probl√®mes\")\n",
    " \n",
    " return model\n",
    " \n",
    " except Exception as e:\n",
    " print(f\"Erreur critique: {e}\")\n",
    " return None\n",
    "\n",
    "# Cr√©ation du mod√®le avec gestion des erreurs\n",
    "if dataset_exists:\n",
    " print(\"TENTATIVE DE CR√âATION DU MOD√àLE...\")\n",
    " model = create_densenet_model()\n",
    " \n",
    " if model is not None:\n",
    "        # Affichage du r√©sum√© du mod√®le (version courte)\n",
    " print(f\"\\n R√âSUM√â DU MOD√àLE\")\n",
    " print(\"=\" * 50)\n",
    " print(f\"Nom: {model.name}\")\n",
    " print(f\"Entr√©e: {model.input_shape}\")\n",
    " print(f\"Sortie: {model.output_shape}\")\n",
    " print(f\"Param√®tres totaux: {model.count_params():,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb809bf4",
   "metadata": {},
   "source": [
    "## Configuration du mod√®le avec MLflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mlflow():\n",
    " \"\"\"\n",
    " Configure MLflow pour le suivi des exp√©riences\n",
    " \"\"\"\n",
    "    # V√©rification de MLflow √† l'int√©rieur de la fonction\n",
    " try:\n",
    " import mlflow\n",
    " import mlflow.tensorflow\n",
    " mlflow_available = True\n",
    " except ImportError:\n",
    " mlflow_available = False\n",
    " \n",
    " if not mlflow_available:\n",
    " print(f\"\\n MLFLOW NON DISPONIBLE\")\n",
    " print(\"=\" * 50)\n",
    " print(\"MLflow n'est pas install√©. Pour l'installer:\")\n",
    " print(\"pip install mlflow\")\n",
    " return False\n",
    " \n",
    " print(f\"\\n CONFIGURATION DE MLFLOW\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    " try:\n",
    "        # Configuration de l'exp√©rience MLflow\n",
    " experiment_name = \"Pneumonia_Detection_DenseNet121\"\n",
    " \n",
    "        # Cr√©ation ou r√©cup√©ration de l'exp√©rience\n",
    " try:\n",
    " experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    " if experiment is None:\n",
    " mlflow.create_experiment(experiment_name)\n",
    " print(f\"Exp√©rience '{experiment_name}' cr√©√©e\")\n",
    " else:\n",
    " print(f\"Exp√©rience '{experiment_name}' trouv√©e\")\n",
    " except:\n",
    " print(f\"Utilisation de l'exp√©rience par d√©faut\")\n",
    " \n",
    " mlflow.set_experiment(experiment_name)\n",
    " \n",
    " return True\n",
    " \n",
    " except Exception as e:\n",
    " print(f\"Erreur MLflow: {e}\")\n",
    " print(\"MLflow sera d√©sactiv√© pour cette session\")\n",
    " return False\n",
    "\n",
    "# Configuration de MLflow\n",
    "mlflow_ready = setup_mlflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ebb42",
   "metadata": {},
   "source": [
    "## Entrainement du mod√®le "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir la classe AVANT la fonction\n",
    "class MLflowEpochLogger(tf.keras.callbacks.Callback):\n",
    " def on_epoch_end(self, epoch, logs=None):\n",
    " if logs:\n",
    " mlflow.log_metrics({\n",
    " \"epoch_train_loss\": logs.get('loss', 0),\n",
    " \"epoch_train_accuracy\": logs.get('accuracy', 0),\n",
    " \"epoch_val_loss\": logs.get('val_loss', 0),\n",
    " \"epoch_val_accuracy\": logs.get('val_accuracy', 0)\n",
    " }, step=epoch)\n",
    "\n",
    "def train_model(model, train_gen, val_gen):\n",
    " \"\"\"\n",
    " Entra√Æne le mod√®le avec suivi MLflow\n",
    " \"\"\"\n",
    " print(f\"\\n ENTRA√éNEMENT DU MOD√àLE\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    " if model is None or train_gen is None:\n",
    " print(\"Mod√®le ou g√©n√©rateur non disponible\")\n",
    " return None\n",
    " \n",
    " try:\n",
    "        # Configuration des callbacks\n",
    " callbacks = [\n",
    " EarlyStopping(\n",
    " monitor='val_loss',\n",
    " patience=5,\n",
    " restore_best_weights=True,\n",
    " verbose=1\n",
    " ),\n",
    " ReduceLROnPlateau(\n",
    " monitor='val_loss',\n",
    " factor=0.5,\n",
    " patience=3,\n",
    " min_lr=1e-7,\n",
    " verbose=1\n",
    " )\n",
    " ]\n",
    " \n",
    " print(f\"Configuration d'entra√Ænement:\")\n",
    " print(f\"- √âpoques: {EPOCHS}\")\n",
    " print(f\"- Batch size: {BATCH_SIZE}\")\n",
    " print(f\"- Learning rate: {LEARNING_RATE}\")\n",
    " print(f\"- Early stopping: patience=5\")\n",
    " print(f\"- Reduce LR: patience=3\")\n",
    " \n",
    "        # D√©marrage du suivi MLflow\n",
    " mlflow_active = False\n",
    " if mlflow_ready:\n",
    " try:\n",
    " mlflow.start_run()\n",
    "                # Log des hyperparam√®tres\n",
    " mlflow.log_params({\n",
    " \"model_architecture\": model.name,\n",
    " \"image_size\": IMG_SIZE,\n",
    " \"batch_size\": BATCH_SIZE,\n",
    " \"learning_rate\": LEARNING_RATE,\n",
    " \"epochs\": EPOCHS,\n",
    " \"optimizer\": \"Adam\",\n",
    " \"loss_function\": \"binary_crossentropy\"\n",
    " })\n",
    " \n",
    "                # Ajout du callback MLflow APR√àS que mlflow_active soit True\n",
    " callbacks.append(MLflowEpochLogger())\n",
    " \n",
    " mlflow_active = True\n",
    " print(\"Hyperparam√®tres logg√©s dans MLflow\")\n",
    " print(\"Callback MLflow ajout√© pour les courbes\")\n",
    " \n",
    " except Exception as e:\n",
    " print(f\"Erreur MLflow: {e}\")\n",
    " \n",
    "        # Entra√Ænement\n",
    " print(f\"\\n D√©but de l'entra√Ænement...\")\n",
    " history = model.fit(\n",
    " train_gen,\n",
    " epochs=EPOCHS,\n",
    " validation_data=val_gen,\n",
    " callbacks=callbacks,\n",
    " verbose=1\n",
    " )\n",
    " \n",
    "        # Log des m√©triques finales dans MLflow\n",
    " if mlflow_active:\n",
    " try:\n",
    " final_metrics = {\n",
    " \"final_train_accuracy\": history.history['accuracy'][-1],\n",
    " \"final_train_loss\": history.history['loss'][-1]\n",
    " }\n",
    " \n",
    " if 'val_accuracy' in history.history:\n",
    " final_metrics[\"final_val_accuracy\"] = history.history['val_accuracy'][-1]\n",
    " final_metrics[\"final_val_loss\"] = history.history['val_loss'][-1]\n",
    " \n",
    " mlflow.log_metrics(final_metrics)\n",
    " \n",
    "                # Sauvegarde du mod√®le dans MLflow\n",
    " mlflow.tensorflow.log_model(model, \"model\")\n",
    " \n",
    " print(\"M√©triques et mod√®le sauvegard√©s dans MLflow\")\n",
    " except Exception as e:\n",
    " print(f\"Erreur lors de la sauvegarde MLflow: {e}\")\n",
    " finally:\n",
    " mlflow.end_run()\n",
    " \n",
    " print(\"Entra√Ænement termin√© avec succ√®s!\")\n",
    " return history\n",
    " \n",
    " except Exception as e:\n",
    " print(f\"Erreur pendant l'entra√Ænement: {e}\")\n",
    " \n",
    "        # Fermeture de MLflow en cas d'erreur\n",
    " if mlflow_active:\n",
    " try:\n",
    " mlflow.end_run()\n",
    " except:\n",
    " pass\n",
    " \n",
    " return None\n",
    "\n",
    "# Entra√Ænement du mod√®le avec gestion d'erreurs\n",
    "if model is not None and train_gen is not None:\n",
    " print(\"LANCEMENT DE L'ENTRA√éNEMENT...\")\n",
    " history = train_model(model, train_gen, val_gen)\n",
    "else:\n",
    " history = None\n",
    " print(\"Entra√Ænement impossible - v√©rifiez les donn√©es et le mod√®le\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baef9c0",
   "metadata": {},
   "source": [
    "## Visualisation des r√©sultats d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed312e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    " \"\"\"\n",
    " Affiche les courbes d'entra√Ænement\n",
    " \"\"\"\n",
    " if history is None:\n",
    " return\n",
    " \n",
    " print(f\"\\n VISUALISATION DES COURBES D'ENTRA√éNEMENT\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    " fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    " \n",
    "    # Courbe de perte (loss)\n",
    " axes[0, 0].plot(history.history['loss'], label='Train Loss', color='blue')\n",
    " axes[0, 0].plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    " axes[0, 0].set_title('√âvolution de la Perte')\n",
    " axes[0, 0].set_xlabel('√âpoque')\n",
    " axes[0, 0].set_ylabel('Perte')\n",
    " axes[0, 0].legend()\n",
    " axes[0, 0].grid(True)\n",
    " \n",
    "    # Courbe de pr√©cision (accuracy)\n",
    " axes[0, 1].plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    " axes[0, 1].plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    " axes[0, 1].set_title('√âvolution de la Pr√©cision')\n",
    " axes[0, 1].set_xlabel('√âpoque')\n",
    " axes[0, 1].set_ylabel('Pr√©cision')\n",
    " axes[0, 1].legend()\n",
    " axes[0, 1].grid(True)\n",
    " \n",
    "    # Courbe de pr√©cision (precision)\n",
    " if 'precision' in history.history:\n",
    " axes[1, 0].plot(history.history['precision'], label='Train Precision', color='blue')\n",
    " axes[1, 0].plot(history.history['val_precision'], label='Validation Precision', color='red')\n",
    " axes[1, 0].set_title('√âvolution de la Pr√©cision (Precision)')\n",
    " axes[1, 0].set_xlabel('√âpoque')\n",
    " axes[1, 0].set_ylabel('Precision')\n",
    " axes[1, 0].legend()\n",
    " axes[1, 0].grid(True)\n",
    " \n",
    "    # Courbe de rappel (recall)\n",
    " if 'recall' in history.history:\n",
    " axes[1, 1].plot(history.history['recall'], label='Train Recall', color='blue')\n",
    " axes[1, 1].plot(history.history['val_recall'], label='Validation Recall', color='red')\n",
    " axes[1, 1].set_title('√âvolution du Rappel (Recall)')\n",
    " axes[1, 1].set_xlabel('√âpoque')\n",
    " axes[1, 1].set_ylabel('Recall')\n",
    " axes[1, 1].legend()\n",
    " axes[1, 1].grid(True)\n",
    " \n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    "\n",
    "# Affichage des courbes\n",
    "if history is not None:\n",
    " plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf285e",
   "metadata": {},
   "source": [
    "## Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94795b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(model, test_generator, save_to_mlflow=True):\n",
    " \"\"\"\n",
    " Calcule et affiche la courbe ROC\n",
    " \"\"\"\n",
    " print(f\"\\n G√âN√âRATION DE LA COURBE ROC\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    " try:\n",
    "        # Reset du g√©n√©rateur\n",
    " test_generator.reset()\n",
    " \n",
    "        # Pr√©dictions probabilistes\n",
    " print(\"Calcul des pr√©dictions...\")\n",
    " y_pred_proba = model.predict(test_generator, verbose=1)\n",
    " \n",
    "        # R√©cup√©ration des vraies labels\n",
    " y_true = test_generator.classes\n",
    " \n",
    "        # Calcul de la courbe ROC\n",
    " fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    " roc_auc = auc(fpr, tpr)\n",
    " \n",
    " print(f\"AUC-ROC calcul√©: {roc_auc:.4f}\")\n",
    " \n",
    "        # Cr√©ation du graphique\n",
    " plt.figure(figsize=(8, 6))\n",
    " plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    " label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    " plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    " label='Random classifier')\n",
    " \n",
    " plt.xlim([0.0, 1.0])\n",
    " plt.ylim([0.0, 1.05])\n",
    " plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    " plt.ylabel('True Positive Rate (Sensitivity)')\n",
    " plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    " plt.legend(loc=\"lower right\")\n",
    " plt.grid(True, alpha=0.3)\n",
    " \n",
    "        # Sauvegarde dans MLflow si activ√©\n",
    " if save_to_mlflow:\n",
    " try:\n",
    "                # V√©rification que MLflow est actif\n",
    " if 'mlflow' in globals() and hasattr(mlflow, 'active_run') and mlflow.active_run():\n",
    " import tempfile\n",
    " import os\n",
    " \n",
    "                    # Sauvegarde temporaire\n",
    " with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:\n",
    " plt.savefig(tmp.name, dpi=300, bbox_inches='tight')\n",
    " \n",
    "                        # Log dans MLflow\n",
    " mlflow.log_artifact(tmp.name, \"plots\")\n",
    " mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    " \n",
    "                        # Nettoyage\n",
    " os.unlink(tmp.name)\n",
    " \n",
    " print(\"Courbe ROC sauvegard√©e dans MLflow\")\n",
    " else:\n",
    " print(\"MLflow non actif - courbe non sauvegard√©e\")\n",
    " except Exception as e:\n",
    " print(f\"Erreur sauvegarde MLflow: {e}\")\n",
    " \n",
    " plt.show()\n",
    " \n",
    "        # Retour des m√©triques\n",
    " return {\n",
    " 'fpr': fpr,\n",
    " 'tpr': tpr,\n",
    " 'thresholds': thresholds,\n",
    " 'auc': roc_auc\n",
    " }\n",
    " \n",
    " except Exception as e:\n",
    " print(f\"Erreur lors du calcul ROC: {e}\")\n",
    " return None\n",
    "\n",
    "print(\"Fonction plot_roc_curve d√©finie avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de la fonction ROC avec le mod√®le entra√Æn√©\n",
    "if 'model' in globals() and 'test_gen' in globals():\n",
    " if model is not None and test_gen is not None:\n",
    " print(\"G√âN√âRATION DE LA COURBE ROC POUR VOTRE MOD√àLE\")\n",
    " print(\"=\" * 60)\n",
    " \n",
    "        # Appel de la fonction ROC\n",
    " roc_results = plot_roc_curve(model, test_gen, save_to_mlflow=True)\n",
    " \n",
    " if roc_results:\n",
    " print(f\"\\n R√âSULTATS ROC:\")\n",
    " print(f\"AUC-ROC: {roc_results['auc']:.4f} ({roc_results['auc']*100:.2f}%)\")\n",
    " \n",
    "            # Interpr√©tation de l'AUC\n",
    " auc_score = roc_results['auc']\n",
    " if auc_score >= 0.9:\n",
    " print(\"üü¢ Excellent mod√®le (AUC ‚â• 0.9)\")\n",
    " elif auc_score >= 0.8:\n",
    " print(\"üü° Bon mod√®le (0.8 ‚â§ AUC < 0.9)\")\n",
    " elif auc_score >= 0.7:\n",
    " print(\"üü† Mod√®le acceptable (0.7 ‚â§ AUC < 0.8)\")\n",
    " else:\n",
    " print(\"Mod√®le faible (AUC < 0.7)\")\n",
    " \n",
    " print(f\"Nombre de seuils: {len(roc_results['thresholds'])}\")\n",
    " \n",
    " else:\n",
    " print(\"Erreur lors du calcul ROC\")\n",
    " else:\n",
    " print(\"Mod√®le ou g√©n√©rateur de test non disponible\")\n",
    " print(\"Variables disponibles:\")\n",
    " print(f\"- model: {model is not None if 'model' in globals() else 'Non d√©fini'}\")\n",
    " print(f\"- test_gen: {test_gen is not None if 'test_gen' in globals() else 'Non d√©fini'}\")\n",
    "else:\n",
    " print(\"Variables 'model' et 'test_gen' non trouv√©es\")\n",
    " print(\"Avez-vous ex√©cut√© l'entra√Ænement du mod√®le ?\")\n",
    " \n",
    "    # Diagnostic des variables disponibles\n",
    " available_vars = [var for var in globals() if not var.startswith('_')]\n",
    " model_vars = [var for var in available_vars if 'model' in var.lower()]\n",
    " data_vars = [var for var in available_vars if any(x in var.lower() for x in ['gen', 'data', 'test'])]\n",
    " \n",
    " print(f\"\\n Variables contenant 'model': {model_vars}\")\n",
    " print(f\"Variables contenant donn√©es: {data_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c9d72",
   "metadata": {},
   "source": [
    "## Evaluation du mod√®le sur le jeu de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbcdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_generator, save_to_mlflow=True):\n",
    " \"\"\"\n",
    " √âvalue le mod√®le sur le jeu de test et affiche les m√©triques\n",
    " \"\"\"\n",
    " if model is None or test_generator is None:\n",
    " return\n",
    " \n",
    " \n",
    " print(f\"\\n √âVALUATION SUR LE JEU DE TEST\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    "    # Pr√©dictions sur le jeu de test\n",
    " print(\"G√©n√©ration des pr√©dictions...\")\n",
    " test_generator.reset()\n",
    " predictions = model.predict(test_generator, verbose=1)\n",
    " \n",
    "    # R√©cup√©ration des vraies labels\n",
    " true_labels = test_generator.classes\n",
    " \n",
    "    # Conversion des pr√©dictions en classes binaires\n",
    " predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    " \n",
    "    # Calcul des m√©triques\n",
    " accuracy = accuracy_score(true_labels, predicted_classes)\n",
    " precision = precision_score(true_labels, predicted_classes)\n",
    " recall = recall_score(true_labels, predicted_classes)\n",
    " f1 = f1_score(true_labels, predicted_classes)\n",
    " \n",
    " print(f\"\\n M√âTRIQUES DE PERFORMANCE:\")\n",
    " print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    " print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    " print(f\"Recall: {recall:.4f} ({recall*100:.2f}%)\")\n",
    " print(f\"F1-Score: {f1:.4f} ({f1*100:.2f}%)\")\n",
    " \n",
    "    # Matrice de confusion\n",
    " cm = confusion_matrix(true_labels, predicted_classes)\n",
    " \n",
    " plt.figure(figsize=(8, 6))\n",
    " sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    " xticklabels=['NORMAL', 'PNEUMONIA'], \n",
    " yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    " plt.title('Matrice de Confusion')\n",
    " plt.ylabel('Vraie Classe')\n",
    " plt.xlabel('Classe Pr√©dite')\n",
    " plt.show()\n",
    " \n",
    "    # Rapport de classification d√©taill√©\n",
    " print(f\"\\n RAPPORT DE CLASSIFICATION D√âTAILL√â:\")\n",
    " print(classification_report(true_labels, predicted_classes, \n",
    " target_names=['NORMAL', 'PNEUMONIA']))\n",
    " \n",
    "    # Log des m√©triques dans MLflow si disponible\n",
    " if mlflow_ready:\n",
    " try:\n",
    " with mlflow.start_run():\n",
    " mlflow.log_metrics({\n",
    " \"test_accuracy\": accuracy,\n",
    " \"test_precision\": precision,\n",
    " \"test_recall\": recall,\n",
    " \"test_f1_score\": f1\n",
    " })\n",
    " print(\"M√©triques de test logg√©es dans MLflow\")\n",
    " except:\n",
    " print(\"Impossible de logger dans MLflow\")\n",
    " \n",
    " return {\n",
    " 'accuracy': accuracy,\n",
    " 'precision': precision,\n",
    " 'recall': recall,\n",
    " 'f1_score': f1,\n",
    " 'confusion_matrix': cm\n",
    " }\n",
    "\n",
    "# √âvaluation du mod√®le\n",
    "if model is not None and test_gen is not None:\n",
    " test_results = evaluate_model(model, test_gen)\n",
    "else:\n",
    " test_results = None\n",
    " print(\"√âvaluation impossible - v√©rifiez le mod√®le et les donn√©es de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7c029",
   "metadata": {},
   "source": [
    "## Sauvegarde du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d677e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename=\"densenet121_pneumonia_model.h5\"):\n",
    " \"\"\"\n",
    " Sauvegarde le mod√®le entra√Æn√©\n",
    " \"\"\"\n",
    " if model is None:\n",
    " return\n",
    " \n",
    " print(f\"\\n SAUVEGARDE DU MOD√àLE\")\n",
    " print(\"=\" * 50)\n",
    " \n",
    " try:\n",
    " model.save(filename)\n",
    " print(f\"Mod√®le sauvegard√©: {filename}\")\n",
    " print(f\"Taille du fichier: {os.path.getsize(filename) / (1024*1024):.1f} MB\")\n",
    " except Exception as e:\n",
    " print(f\"Erreur lors de la sauvegarde: {e}\")\n",
    "\n",
    "# Sauvegarde du mod√®le\n",
    "if model is not None:\n",
    " save_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pneumonia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}